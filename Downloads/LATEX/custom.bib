% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").
@article{choi2018fine,
  title={Fine-grained attention mechanism for neural machine translation},
  author={Choi, Heeyoul and Cho, Kyunghyun and Bengio, Yoshua},
  journal={Neurocomputing},
  volume={284},
  pages={171--176},
  year={2018},
  publisher={Elsevier}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{peters-etal-2018-deep,
    title = "Deep Contextualized Word Representations",
    author = "Peters, Matthew E.  and
      Neumann, Mark  and
      Iyyer, Mohit  and
      Gardner, Matt  and
      Clark, Christopher  and
      Lee, Kenton  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1202",
    doi = "10.18653/v1/N18-1202",
    pages = "2227--2237",
    abstract = "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
}

@article{amrami2018word,
  title={Word sense induction with neural biLM and symmetric patterns},
  author={Amrami, Asaf and Goldberg, Yoav},
  journal={arXiv preprint arXiv:1808.08518},
  year={2018}
}

@inproceedings{schmidt-wiegand-2017-survey,
    title = "A Survey on Hate Speech Detection using Natural Language Processing",
    author = "Schmidt, Anna  and
      Wiegand, Michael",
    booktitle = "Proceedings of the Fifth International Workshop on Natural Language Processing for Social Media",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W17-1101",
    doi = "10.18653/v1/W17-1101",
    pages = "1--10",
    abstract = "This paper presents a survey on hate speech detection. Given the steadily growing body of social media content, the amount of online hate speech is also increasing. Due to the massive scale of the web, methods that automatically detect hate speech are required. Our survey describes key areas that have been explored to automatically recognize these types of utterances using natural language processing. We also discuss limits of those approaches.",
}

@inproceedings{waseem-etal-2017-understanding,
    title = "Understanding Abuse: A Typology of Abusive Language Detection Subtasks",
    author = "Waseem, Zeerak  and
      Davidson, Thomas  and
      Warmsley, Dana  and
      Weber, Ingmar",
    booktitle = "Proceedings of the First Workshop on Abusive Language Online",
    month = aug,
    year = "2017",
    address = "Vancouver, BC, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W17-3012",
    doi = "10.18653/v1/W17-3012",
    pages = "78--84",
    abstract = "As the body of research on abusive language detection and analysis grows, there is a need for critical consideration of the relationships between different subtasks that have been grouped under this label. Based on work on hate speech, cyberbullying, and online abuse we propose a typology that captures central similarities and differences between subtasks and discuss the implications of this for data annotation and feature construction. We emphasize the practical actions that can be taken by researchers to best approach their abusive language detection subtask of interest.",
}

@inproceedings{hateoffensive,
  title = {Automated Hate Speech Detection and the Problem of Offensive Language},
  author = {Davidson, Thomas and Warmsley, Dana and Macy, Michael and Weber, Ingmar}, 
  booktitle = {Proceedings of the 11th International AAAI Conference on Web and Social Media},
  series = {ICWSM '17},
  year = {2017},
  location = {Montreal, Canada},
  pages = {512-515}
  }

@article{DBLP:journals/corr/abs-1909-12642,
  author    = {Punyajoy Saha and
               Binny Mathew and
               Pawan Goyal and
               Animesh Mukherjee},
  title     = {HateMonitors: Language Agnostic Abuse Detection in Social Media},
  journal   = {CoRR},
  volume    = {abs/1909.12642},
  year      = {2019},
  url       = {http://arxiv.org/abs/1909.12642},
  eprinttype = {arXiv},
  eprint    = {1909.12642},
  timestamp = {Thu, 24 Jun 2021 13:18:19 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1909-12642.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/corr/abs-2111-14830,
  author    = {Mithun Das and
               Somnath Banerjee and
               Punyajoy Saha},
  title     = {Abusive and Threatening Language Detection in Urdu using Boosting
               based and {BERT} based models: {A} Comparative Approach},
  journal   = {CoRR},
  volume    = {abs/2111.14830},
  year      = {2021},
  url       = {https://arxiv.org/abs/2111.14830},
  eprinttype = {arXiv},
  eprint    = {2111.14830},
  timestamp = {Thu, 07 Apr 2022 07:42:38 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2111-14830.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{bjorck2018understanding,
  title={Understanding batch normalization},
  author={Bjorck, Nils and Gomes, Carla P and Selman, Bart and Weinberger, Kilian Q},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{karan-snajder-2018-cross,
    title = "Cross-Domain Detection of Abusive Language Online",
    author = "Karan, Mladen  and
      {\v{S}}najder, Jan",
    booktitle = "Proceedings of the 2nd Workshop on Abusive Language Online ({ALW}2)",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W18-5117",
    doi = "10.18653/v1/W18-5117",
    pages = "132--137",
    abstract = "We investigate to what extent the models trained to detect general abusive language generalize between different datasets labeled with different abusive language types. To this end, we compare the cross-domain performance of simple classification models on nine different datasets, finding that the models fail to generalize to out-domain datasets and that having at least some in-domain data is important. We also show that using the frustratingly simple domain adaptation (Daume III, 2007) in most cases improves the results over in-domain training, especially when used to augment a smaller dataset with a larger one.",
}

@article{elsherief2021latent,
  title={Latent hatred: A benchmark for understanding implicit hate speech},
  author={ElSherief, Mai and Ziems, Caleb and Muchlinski, David and Anupindi, Vaishnavi and Seybolt, Jordyn and De Choudhury, Munmun and Yang, Diyi},
  journal={arXiv preprint arXiv:2109.05322},
  year={2021}
}

@article{DBLP:journals/corr/abs-0907-1815,
  author    = {Hal Daum{\'{e}} III},
  title     = {Frustratingly Easy Domain Adaptation},
  journal   = {CoRR},
  volume    = {abs/0907.1815},
  year      = {2009},
  url       = {http://arxiv.org/abs/0907.1815},
  eprinttype = {arXiv},
  eprint    = {0907.1815},
  timestamp = {Mon, 13 Aug 2018 16:46:20 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-0907-1815.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{wang-etal-2020-detect,
    title = "Detect All Abuse! Toward Universal Abusive Language Detection Models",
    author = "Wang, Kunze  and
      Lu, Dong  and
      Han, Caren  and
      Long, Siqu  and
      Poon, Josiah",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2020.coling-main.560",
    doi = "10.18653/v1/2020.coling-main.560",
    pages = "6366--6376",
    abstract = "Online abusive language detection (ALD) has become a societal issue of increasing importance in recent years. Several previous works in online ALD focused on solving a single abusive language problem in a single domain, like Twitter, and have not been successfully transferable to the general ALD task or domain. In this paper, we introduce a new generic ALD framework, MACAS, which is capable of addressing several types of ALD tasks across different domains. Our generic framework covers multi-aspect abusive language embeddings that represent the target and content aspects of abusive language and applies a textual graph embedding that analyses the user{'}s linguistic behaviour. Then, we propose and use the cross-attention gate flow mechanism to embrace multiple aspects of abusive language. Quantitative and qualitative evaluation results show that our ALD algorithm rivals or exceeds the six state-of-the-art ALD algorithms across seven ALD datasets covering multiple aspects of abusive language and different online community domains.",
}

@article{kutuzov2021large,
  title={Large-scale contextualised language modelling for norwegian},
  author={Kutuzov, Andrey and Barnes, Jeremy and Velldal, Erik and {\O}vrelid, Lilja and Oepen, Stephan},
  journal={arXiv preprint arXiv:2104.06546},
  year={2021}
}


